{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoComplete Model Using N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from autocomplete_model import AutoComplete\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing training data...\n",
      "[['how', 'are', 'you', '?', 'btw', 'thanks', 'for', 'the', 'rt', '.', 'you', 'gon', 'na', 'be', 'in', 'dc', 'anytime', 'soon', '?', 'love', 'to', 'see', 'you', '.', 'been', 'way', ',', 'way', 'too', 'long', '.'], ['when', 'you', 'meet', 'someone', 'special', '...', 'you', \"'ll\", 'know', '.', 'your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', 'you', \"'ll\", 'smile', 'for', 'no', 'reason', '.'], ['they', \"'ve\", 'decided', 'its', 'more', 'fun', 'if', 'i', 'do', \"n't\", '.'], ['so', 'tired', 'd', ';', 'played', 'lazer', 'tag', '&', 'ran', 'a', 'lot', 'd', ';', 'ughh', 'going', 'to', 'sleep', 'like', 'in', '5', 'minutes', ';', ')'], ['words', 'from', 'a', 'complete', 'stranger', '!', 'made', 'my', 'birthday', 'even', 'better', ':', ')'], ['first', 'cubs', 'game', 'ever', '!', 'wrigley', 'field', 'is', 'gorgeous', '.', 'this', 'is', 'perfect', '.', 'go', 'cubs', 'go', '!'], ['i', 'no', '!', 'i', 'get', 'another', 'day', 'off', 'from', 'skool', 'due', 'to', 'the', 'wonderful', 'snow', '(', ':', 'and', 'this', 'wakes', 'me', 'up', '...', 'damn', 'thing'], ['i', \"'m\", 'coo', '...', 'jus', 'at', 'work', 'hella', 'tired', 'r', 'u', 'ever', 'in', 'cali'], ['the', 'new', 'sundrop', 'commercial', '...', 'hehe', 'love', 'at', 'first', 'sight'], ['we', 'need', 'to', 'reconnect', 'this', 'week'], ['i', 'always', 'wonder', 'how', 'the', 'guys', 'on', 'the', 'auctions', 'shows', 'learned', 'to', 'talk', 'so', 'fast', '!', '?', 'all', 'i', 'hear', 'is', 'djsosnekspqnslanskam', '.'], ['dammnnnnn', 'what', 'a', 'catch'], ['such', 'a', 'great', 'picture', '!', 'the', 'green', 'shirt', 'totally', 'brings', 'out', 'your', 'eyes', '!'], ['desk', 'put', 'together', ',', 'room', 'all', 'set', 'up', '.', 'oh', 'boy', ',', 'oh', 'boy'], ['i', \"'m\", 'doing', 'it', '!', 'ðŸ‘¦'], ['beauty', 'brainstorming', 'in', 'the', 'alchemy', 'office', 'with', 'and', 'sally', 'walker', '!'], ['looking', 'for', 'a', 'new', 'band', 'to', 'blog', 'for', 'the', 'month', '.', 'anyone', 'interested', '?'], ['packing', 'for', 'a', 'quick', 'move', 'down', 'the', 'street', '...', 'if', 'only', 'i', 'had', 'some', 'movers', '...'], ['ford', 'focus', 'hatchback', '?'], ['rt', ':', 'according', 'to', 'the', 'national', 'retail', 'federation', '$', '16.3', 'billion', 'was', 'spent', 'on', '#', 'mothersday', 'last', 'year', '!', '!']]\n",
      "Extracting vocabulary...\n",
      "Processing unknown Tokens in training data...\n",
      "Computing n-gram counts with n = 1 of 5...\n",
      "Computing n-gram counts with n = 2 of 5...\n",
      "Computing n-gram counts with n = 3 of 5...\n",
      "Computing n-gram counts with n = 4 of 5...\n",
      "Computing n-gram counts with n = 5 of 5...\n",
      "The model has been successfully fit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autocomplete_model.AutoComplete at 0x1adef4f22b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/en_US.twitter.txt\", \"r\") as f:\n",
    "    train_data = f.read()\n",
    "\n",
    "autoc = AutoComplete()\n",
    "autoc.fit(train_data, n_grams_up_to= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('much', 0.016803400217455768),\n",
       " ('excited', 0.000472561876070648),\n",
       " ('excited', 0.0004135404974301412),\n",
       " ('excited', 0.00023658839533920861)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am so\"\n",
    "autoc.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it the first letter of the next word (We can give more than one letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excited', 0.004200850054363942),\n",
       " ('excited', 0.000472561876070648),\n",
       " ('excited', 0.0004135404974301412),\n",
       " ('excited', 0.00023658839533920861)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoc.predict(sentence, start_with= \"e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try a counple more sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 0.03896969024092373),\n",
       " ('to', 0.00177294486141481),\n",
       " ('to', 0.00017764092846991948),\n",
       " ('to', 0.00017764092846991948)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \" I am not going\"\n",
    "autoc.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('home', 0.00038858665482402574),\n",
       " ('how', 5.9098162047160334e-05),\n",
       " ('how', 5.921364282330649e-05),\n",
       " ('how', 5.921364282330649e-05)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoc.predict(sentence, start_with= \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 0.000764481034989709),\n",
       " ('the', 0.00029566554313760273),\n",
       " ('how', 5.922065616487031e-05),\n",
       " ('how', 5.922065616487031e-05)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"if I wanted to visit\"\n",
    "autoc.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to randomly choose our next word from prediction and go with it by addding 10 words to the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the\n",
      "where is the best\n",
      "where is the best place\n",
      "where is the best place to\n",
      "where is the best place to be\n",
      "where is the best place to be a\n",
      "where is the best place to be a great\n",
      "where is the best place to be a great day\n",
      "where is the best place to be a great day !\n",
      "where is the best place to be a great day ! <e>\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "choices= random.choices(range(4), k= k)\n",
    "sentence = \"where is\"\n",
    "\n",
    "for i in range(k):\n",
    "    sentence = sentence + \" \" + autoc.predict(sentence)[choices[i]][0]\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to go with first prediction for a few steps, then restart and go back with other choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if I 'm\n",
      "if I 'm not\n",
      "if I 'm not a\n",
      "if I 'm not a <unk>\n",
      "if I 'm not a <unk> >\n",
      "\n",
      "if I can\n",
      "if I can not\n",
      "if I can not wait\n",
      "if I can not wait to\n",
      "if I can not wait to see\n",
      "\n",
      "if I had\n",
      "if I had a\n",
      "if I had a great\n",
      "if I had a great time\n",
      "if I had a great time !\n",
      "\n",
      "if I had\n",
      "if I had a\n",
      "if I had a gun\n",
      "if I had a gun ...\n",
      "if I had a gun ... oh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "\n",
    "    sentence = \"if I\"\n",
    "\n",
    "    for j in range(5):\n",
    "        sentence = sentence + \" \" + autoc.predict(sentence)[i][0]\n",
    "        print(sentence)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
